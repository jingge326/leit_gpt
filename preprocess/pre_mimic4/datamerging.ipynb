{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "aaf757a1-7eff-4403-83e7-59f49afa9d0c",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pathlib\n",
                "import pandas as pd\n",
                "from datetime import timedelta\n",
                "\n",
                "\n",
                "p_project = str(pathlib.Path(os.getcwd()).parents[1])\n",
                "path_temp = p_project + '/data/mimic4'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "2b3ea463-3189-4d2d-ac33-3091098b733c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/xiao/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3398: DtypeWarning: Columns (12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
                        "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
                        "/home/xiao/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3398: DtypeWarning: Columns (8,11,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
                        "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
                        "/tmp/ipykernel_22592/1294378690.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  complete_df[name] = 0.0\n",
                        "/tmp/ipykernel_22592/1294378690.py:84: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
                        "  complete_df[name2] = 0\n"
                    ]
                }
            ],
            "source": [
                "lab_df = pd.read_csv(path_temp + '/processed/tables/lab_processed.csv')[\n",
                "    ['subject_id', 'hadm_id', 'charttime', 'valuenum', 'label']]\n",
                "inputs_df = pd.read_csv(path_temp + '/processed/tables/inputs_processed.csv')[\n",
                "    ['subject_id', 'hadm_id', 'charttime', 'amount', 'label']]\n",
                "outputs_df = pd.read_csv(path_temp + '/processed/tables/outputs_processed.csv')[\n",
                "    ['subject_id', 'hadm_id', 'charttime', 'value', 'label']]\n",
                "presc_df = pd.read_csv(path_temp + '/processed/tables/prescriptions_processed.csv')[\n",
                "    ['subject_id', 'hadm_id', 'charttime', 'dose_val_rx', 'drug']]\n",
                "\n",
                "# Change the name of amount. Valuenum for every table\n",
                "inputs_df['valuenum'] = inputs_df['amount']\n",
                "inputs_df = inputs_df.drop(columns=['amount']).copy()\n",
                "\n",
                "outputs_df['valuenum'] = outputs_df['value']\n",
                "outputs_df = outputs_df.drop(columns=['value']).copy()\n",
                "\n",
                "presc_df['valuenum'] = presc_df['dose_val_rx']\n",
                "presc_df = presc_df.drop(columns=['dose_val_rx']).copy()\n",
                "presc_df['label'] = presc_df['drug']\n",
                "presc_df = presc_df.drop(columns=['drug']).copy()\n",
                "\n",
                "# Tag to distinguish between lab and inputs events\n",
                "inputs_df['Origin'] = 'Inputs'\n",
                "lab_df['Origin'] = 'Lab'\n",
                "outputs_df['Origin'] = 'Outputs'\n",
                "presc_df['Origin'] = 'Prescriptions'\n",
                "\n",
                "# merge both dfs.\n",
                "merged_df1 = (inputs_df.append(lab_df)).reset_index()\n",
                "merged_df2 = (merged_df1.append(outputs_df)).reset_index()\n",
                "merged_df2.drop(columns='level_0', inplace=True)\n",
                "merged_df = (merged_df2.append(presc_df)).reset_index()\n",
                "\n",
                "# Check that all labels have different names.\n",
                "assert(merged_df['label'].nunique() == (inputs_df['label'].nunique(\n",
                ")+lab_df['label'].nunique()+outputs_df['label'].nunique()+presc_df['label'].nunique()))\n",
                "\n",
                "# set the timestamp as the time delta between the first chart time for each admission\n",
                "merged_df['charttime'] = pd.to_datetime(\n",
                "    merged_df['charttime'], format='%Y-%m-%d %H:%M:%S')\n",
                "ref_time = merged_df.groupby('hadm_id')['charttime'].min()\n",
                "merged_df_1 = pd.merge(ref_time.to_frame(name='ref_time'),\n",
                "                       merged_df, left_index=True, right_on='hadm_id')\n",
                "merged_df_1['time_stamp'] = merged_df_1['charttime']-merged_df_1['ref_time']\n",
                "assert(len(merged_df_1.loc[merged_df_1['time_stamp']\n",
                "       < timedelta(hours=0)].index) == 0)\n",
                "\n",
                "# Create a label code (int) for the labels.\n",
                "label_dict = dict(zip(list(merged_df_1['label'].unique()), range(\n",
                "    len(list(merged_df_1['label'].unique())))))\n",
                "merged_df_1['label_code'] = merged_df_1['label'].map(label_dict)\n",
                "\n",
                "label_dict_df = pd.Series(merged_df_1['label'].unique()).reset_index()\n",
                "label_dict_df.columns = ['index', 'label']\n",
                "label_dict_df['label_code'] = label_dict_df['label'].map(label_dict)\n",
                "label_dict_df.drop(columns=['index'], inplace=True)\n",
                "label_dict_df.to_csv(path_temp + '/processed/tables/label_dict.csv')\n",
                "\n",
                "# select only values within first 24 hours\n",
                "merged_df_short = merged_df_1[['hadm_id', 'valuenum', 'time_stamp', 'label_code', 'Origin']].rename(\n",
                "    columns={'hadm_id': 'ID', 'time_stamp': 'Time'})\n",
                "merged_df_short = merged_df_short.loc[(\n",
                "    merged_df_short['Time'] < timedelta(hours=24))]\n",
                "\n",
                "# The sampling interval is 1 minute\n",
                "merged_df_short['Time'] = merged_df_short['Time'].dt.total_seconds().div(\n",
                "    60).astype(int)\n",
                "assert(len(merged_df_short.loc[merged_df_short['Time'] > 1440].index) == 0)\n",
                "\n",
                "# drop columns that are not needed for final dataset\n",
                "merged_df_short.drop(['Origin'], axis=1, inplace=True)\n",
                "complete_df = merged_df_short\n",
                "\n",
                "# create value- and mask- columns and fill with data\n",
                "labels = complete_df['label_code'].unique()\n",
                "value_columns = []\n",
                "mask_columns = []\n",
                "for num in labels:\n",
                "    name = 'Value_label_' + str(num)\n",
                "    name2 = 'Mask_label_' + str(num)\n",
                "    value_columns.append(name)\n",
                "    mask_columns.append(name2)\n",
                "    complete_df[name] = 0.0\n",
                "    complete_df[name2] = 0\n",
                "    # complete_df[name] = complete_df[name].astype(float)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "1642c087-c58c-4b9f-ad98-3322608d4f54",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(7253647, 196)"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "complete_df.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "d6529150-86fd-4886-9a7f-410a29829c07",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(7227943, 196)"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "complete_df.dropna(inplace=True)\n",
                "complete_df.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "f00526d0-1409-45fe-a8fc-246f80cf2626",
            "metadata": {},
            "outputs": [],
            "source": [
                "for index, row in complete_df.iterrows():\n",
                "    name = 'Value_label_' + str(row['label_code'].astype(int))\n",
                "    name2 = 'Mask_label_' + str(row['label_code'].astype(int))\n",
                "    complete_df.at[index, name] = row['valuenum']\n",
                "    complete_df.at[index, name2] = 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "53ab9859-48b8-4cb9-8b83-3469ab9d115d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# drop all unneccesary columns and do sanity check\n",
                "complete_df.drop(['valuenum', 'label_code'], axis=1, inplace=True)\n",
                "\n",
                "# If there are multiple values for the same time stamp, take the maximum\n",
                "complete_df_gb = complete_df.groupby(['ID', 'Time'], as_index=False).max()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "48b3c6b0-f2ed-4210-b4b9-843e81b3a592",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "55181"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "for x in mask_columns:\n",
                "    assert(len(complete_df_gb.loc[complete_df_gb[x] > 1]) == 0)\n",
                "complete_df_gb['ID'] = complete_df_gb['ID'].astype(int)\n",
                "\n",
                "complete_df_gb['ID'].nunique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "d486e144-35a3-45cf-b683-9b1ce9d93e55",
            "metadata": {},
            "outputs": [],
            "source": [
                "complete_df_gb.to_csv(\n",
                "    path_temp + '/processed/tables/mimic4_full_dataset.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a99b6a6b-f917-4b3f-91b3-457aaeaf3837",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.12 ('transfer_ehr')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.12"
        },
        "vscode": {
            "interpreter": {
                "hash": "5ae865abb88ad0a991db65fb0a3113ce9d7dd5f50b65ef8b203d3356ff36831c"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}